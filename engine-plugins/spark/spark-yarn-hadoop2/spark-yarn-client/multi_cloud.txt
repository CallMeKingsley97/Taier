多集群兼容：请求样例

{
	"taskType": 0,
	"sqlText": "select 1 from dual",
	"computeType": 1,
	"name": "create_xc_table",
	"engineType": "spark",
	"taskParams": "##Number of CPU cores need driver program is running\ndriver.cores=2\n\n##Each Spark action (collect) limits the total size of the serialized results of all partitions. Setting value should not be less than 1M, 0 means no limit. If the total exceeds this limit, the program will terminate. Limit values may cause memory overflow error driver (dependent on spark. driver. memory and objects in the JVM's memory consumption).\n##driver.maxResultSize=1g\n\n##Driver number memory used by a process\n##driver.memory=512m\n\n\n##Amount of memory used by each executor process. And JVM memory strings have the same format (for example, 512m, 2G)\n##executor.memory=512m\n\n\n##Amount of memory used by each executor process. And JVM memory strings have the same format (for example, 512m, 2G)\n##logConf=spark.logConf",
	"taskId": "id001",
	"pluginInfo": {
		"typeName":"spark_yarn",
		"hadoopConf": {
			"dfs.nameservices": "ns1",
			"fs.defaultFS": "hdfs://ns1",
			"dfs.ha.namenodes.ns1": "nn1,nn2",
			"dfs.namenode.rpc-address.ns1.nn1": "node02:9000",
			"dfs.namenode.rpc-address.ns1.nn2": "node03:9000"
		},
		"yarnConf": {
			"yarn.resourcemanager.ha.rm-ids": "rm1,rm2",
			"yarn.resourcemanager.address.rm1": "node02:8032",
			"yarn.resourcemanager.address.rm2": "node03:8032",
			"yarn.resourcemanager.webapp.address.rm1":"node02:8088",
			"yarn.resourcemanager.webapp.address.rm2":"node03:8088",
			"yarn.resourcemanager.ha.enabled": "true"
		},
		"md5sum":"ee620eb228741591e94656f7e11e0b32",
		"confHdfsPath":"hdfs://ns1/kepa/node02conf"
	}
}