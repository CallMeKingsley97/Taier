#engine
slots: 10
localAddress: localhost:8080
nodeZkAddress: node01:2181,node02:2181,node03:2181/xc_engine
exeQueueSize: 1
#debug模式关闭数据校验
isDebug: true

#选配参数--如果包含mysql,oracle,sqlserver插件则需要该配置,存储元数据信息
db:
   url: jdbc:mysql://172.16.8.104:3306/rdos?charset=utf8&autoReconnect=true
   userName: dtstack
   pwd: abc123

engineTypes:
    #-
    #    typeName: flink120
    #    flinkZkAddress: 172.16.10.135:2181,172.16.10.136:2181,172.16.10.138:2181
    #    flinkZkNamespace: /flink120ha
    #    flinkClusterId: /default
    #    flinkHighAvailabilityStorageDir: hdfs://172.16.10.135:9000/flink120ha/ha
    #    jarTmpDir: ../tmp
    #    sqlPluginRootDir: ./sqlplugin
    #    remotePluginRootDir: /opt/dtstack/flinksqlplugin

    #-
#
    #    typeName: flink130
    #    clusterMode: standalone
    #    flinkZkAddress: node01:2181,node02:2181,node03:2181
    #    flinkZkNamespace: /flink130
    #    flinkHighAvailabilityStorageDir: hdfs://ns1/flink130/ha
    #    jarTmpDir: ../tmp130
    #    flinkPluginRoot: D:\gitspace\rdos-execution-engine\flinkplugin
    #    remotePluginRootDir: /opt/dtstack/flinkplugin
    #    monitorAddress: node02:8081,node03:8081
        #yarnConfPath: D:\yarn-site.xml

    #-
    #    typeName: flink140
    #    clusterMode: standalone
    #    flinkZkAddress: 172.16.8.104:2181,172.16.8.105:2181,172.16.8.106:2181
    #    flinkHighAvailabilityStorageDir: hdfs://ns1/flink140/ha
    #    flinkZkNamespace: /flink140
    #    jarTmpDir: ../tmp140
    #    flinkPluginRoot: D:\gitspace\rdos-execution-engine\flinkplugin
    #    remotePluginRootDir: /opt/dtstack/flinkplugin
    #    monitorAddress: node02:8081,node03:8081
        #yarnConfPath: D:\yarn-site.xml


    -
        typeName: flink140
        clusterMode: yarn
        flinkZkAddress: node01:2181,node02:2181,node03:2181
        #简化为只配置/flink140/ha
        flinkHighAvailabilityStorageDir: hdfs://ns1/flink140/ha
        #flinkZkNamespace: /flink140
        #jarTmpDir: ../tmp140
        flinkPluginRoot: D:\gitspace\rdos-execution-engine\flinkplugin
        #remotePluginRootDir: /opt/dtstack/flinkplugin
        #hadoopConf:
        #    dfs.nameservices: ns1
        #    fs.defaultFS: hdfs://ns1
        #    dfs.ha.namenodes.ns1: nn1,nn2
        #    dfs.namenode.rpc-address.ns1.nn1: node02:9000
        #    dfs.namenode.rpc-address.ns1.nn2: node03:9000
        #    #dfs.client.failover.proxy.provider.ns1: org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
        #    #fs.hdfs.impl.disable.cache: true
        #yarnConf:
        #    yarn.resourcemanager.address.rm1: node02:8032
        #    yarn.resourcemanager.address.rm2: node03:8032
        #    yarn.resourcemanager.ha.rm-ids: rm1,rm2
        #    yarn.resourcemanager.ha.enabled: true


    #-
    #    typeName: flink140
    #    clusterMode: standalone
    #    flinkJobMgrUrl: localhost:6123
    #    jarTmpDir: ../tmp140
    #    flinkPluginRoot: E:\flinkplugin
    #    remotePluginRootDir: E:\flinkplugin

    #-
    #    typeName: spark_yarn
    #    sparkYarnArchive: hdfs://ns1/sparkjars/jars
    #    sparkSqlProxyPath: hdfs://ns1/user/spark/spark-0.0.1-SNAPSHOT.jar
    #    sparkSqlProxyMainClass: com.dtstack.sql.main.SqlProxy
    #    sparkPythonExtLibPath: hdfs://ns1/pythons/pyspark.zip,hdfs://ns1/pythons/py4j-0.10.4-src.zip

    #-
    #    typeName: datax
    #    dataxSSHAddress: 172.16.1.155 #可以多个
    #    userName: root
    #    password: abc123 #可以不填 打通ssh免登陆
    #    dataxBinDir: /opt/dtstack/datax/bin

    #-
    #    typeName: spark
    #    sparkWebMaster: node03:8080,node02:8080
    #    sparkMaster: spark://node03:6066,node02:6066
    #    sparkSqlProxyPath: hdfs://ns1/user/spark/spark-0.0.1-SNAPSHOT.jar
    #    sparkSqlProxyMainClass: com.dtstack.sql.main.SqlProxy

    #-
    #    typeName: mysql
    #    dbUrl: jdbc:mysql://172.16.8.104:3306/rdos?charset=utf8
    #    userName: dtstack
    #    pwd: abc123

    #-
    #    typeName: spark_yarn
    #    sparkYarnArchive: hdfs://kudu1:9000/sparkjars/jars
    #    sparkSqlProxyPath: hdfs://kudu1:9000/hyf/spark-0.0.1-SNAPSHOT.jar
    #    sparkSqlProxyMainClass: com.dtstack.sql.main.SqlProxy
    #    sparkPythonExtLibPath: hdfs://kudu1:9000/pythons/pyspark.zip,hdfs://kudu1/pythons/py4j-0.10.4-src.zip